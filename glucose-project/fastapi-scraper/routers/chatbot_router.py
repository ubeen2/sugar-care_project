from fastapi import APIRouter
from fastapi import UploadFile, File
from fastapi import APIRouter, UploadFile, File
from services.chatbot_service import ask_chatbot
from services.google_voice_service import speech_to_text, text_to_speech
from pydub import AudioSegment
import os

router = APIRouter(prefix="/chatbot")
@router.post("/chat")
def chat_endpoint(payload: dict):
    message = payload.get("message", "").strip()
    answer = ask_chatbot(message)

    # ë§Œì•½ ì§ˆë¬¸ì´ ë¹„ì–´ìˆë‹¤ë©´ í•´ë‹¹ ë©”ì‹œì§€ë¥¼ ì¶œë ¥
    if message == "":
        return { "answer": "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤." }

    print(f"[ì‚¬ìš©ì ì§ˆë¬¸] {message}")
    print(f"[ì±—ë´‡ ì‘ë‹µ] {answer}")

    return answer

@router.post("/reset_chat")
def reset_endpoint():
    return reset_chatbot()

# ğŸ™ï¸ ìŒì„± ì…ë ¥ â†’ STT â†’ ì±—ë´‡ ì‘ë‹µ â†’ TTS íŒŒì¼ ìƒì„±
# @router.post("/voice_chat")
# async def voice_chat(file: UploadFile = File(...)):
#     temp_path = f"./temp_{file.filename}"
#     with open(temp_path, "wb") as f:
#         f.write(await file.read())
#
#     user_text = speech_to_text(temp_path)
#     os.remove(temp_path)
#
#     print("ğŸ—£ï¸ Google STT ê²°ê³¼:", user_text)
#
#
#     answer = ask_chatbot(user_text)["answer"]
#
#     tts_file = text_to_speech(answer)
#
#     return {
#         "user_text": user_text,
#         "bot_answer": answer,
#         "tts_file": tts_file
#     }

# @router.post("/voice_chat")
# async def voice_chat(file: UploadFile = File(...)):
#     temp_path = f"./temp_{file.filename}"
#
#     # 1ï¸âƒ£ íŒŒì¼ ì €ì¥
#     with open(temp_path, "wb") as f:
#         f.write(await file.read())
#     print(f"[DEBUG] íŒŒì¼ ì €ì¥ë¨: {temp_path}, í¬ê¸°: {len(content)} bytes")
#
#     #webM->Wav ë³€í™˜
#     wav_path = temp_path.replace(".webm", ".wav")
#     audio = AudioSegment.from_file(temp_path)
#     audio = audio.set_channels(1).set_frame_rate(16000)
#     audio.export(wav_path, format="wav")
#
#     # 2ï¸âƒ£ STT í˜¸ì¶œ
#     user_text = speech_to_text(wav_path)
#     print(f"[DEBUG] Clova STT ì „ì²´ ì‘ë‹µ: {user_text}")
#
#     # íŒŒì¼ ì‚­ì œ
#     os.remove(temp_path)
#
#     # 3ï¸âƒ£ ì±—ë´‡ ì²˜ë¦¬
#     answer = ask_chatbot(user_text)["answer"]
#
#     # 4ï¸âƒ£ TTS(base64)
#     tts_audio = text_to_speech(answer)
#
#     os.remove(wav_path)
#
#     return {
#         "user_text": user_text,
#         "bot_answer": answer,
#         "tts_audio": tts_audio
#     }
#
# # ğŸ§ ìƒì„±ëœ mp3 íŒŒì¼ ë°˜í™˜ìš©
# from fastapi.responses import FileResponse
#
# @router.get("/tts/{filename}")
# async def get_tts(filename: str):
#     file_path = os.path.join("./tts_cache", filename)
#     return FileResponse(file_path, media_type="audio/mpeg")



@router.post("/voice_chat")
async def voice_chat(file: UploadFile = File(...)):
    temp_path = f"./temp_{file.filename}"

    # 1ï¸âƒ£ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥
    content = await file.read()
    with open(temp_path, "wb") as f:
        f.write(content)
    print(f"[DEBUG] íŒŒì¼ ì €ì¥ë¨: {temp_path}, í¬ê¸°: {len(content)} bytes")

    # 2ï¸âƒ£ WebM â†’ WAV ë³€í™˜ (ëª¨ë…¸, 16kHz)
    wav_path = temp_path.replace(".webm", ".wav")
    audio = AudioSegment.from_file(temp_path)
    audio = audio.set_channels(1).set_frame_rate(16000)
    audio.export(wav_path, format="wav", codec="pcm_s16le")

    # 3ï¸âƒ£ Clova STT í˜¸ì¶œ
    try:
        user_text = speech_to_text(wav_path)
    except Exception as e:
        user_text = ""
        print(f"[ERROR] STT ì‹¤íŒ¨: {e}")

    print(f"[DEBUG] Clova STT ê²°ê³¼: {user_text}")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(temp_path)
    os.remove(wav_path)

    # 4ï¸âƒ£ ì±—ë´‡ ì²˜ë¦¬
    answer = ask_chatbot(user_text)["answer"]

    # 5ï¸âƒ£ Google TTS â†’ Base64
    tts_audio = text_to_speech(answer)

    return {
        "user_text": user_text,
        "bot_answer": answer,
        "tts_audio": tts_audio
    }
